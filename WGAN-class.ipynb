{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein GAN for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WGAN(object):\n",
    "    def __init__(self, mb_size = 32, X_dim = 784, z_dim = 20, h_dim = 128):\n",
    "        self.mb_size = mb_size\n",
    "        self.X_dim = X_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.h_dim = h_dim\n",
    "        \n",
    "        self.define_params()\n",
    "        \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "        return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
    "    \n",
    "    def define_params(self):\n",
    "        mb_size = self.mb_size\n",
    "        X_dim = self.X_dim    \n",
    "        z_dim = self.z_dim    \n",
    "        h_dim = self.h_dim    \n",
    "    \n",
    "        # discriminator params\n",
    "        X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "\n",
    "        D_W1 = tf.Variable(self.xavier_init([X_dim, h_dim]))\n",
    "        D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "        D_W2 = tf.Variable(self.xavier_init([h_dim, 1]))\n",
    "        D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "        theta_D = [D_W1, D_W2, D_b1, D_b2]\n",
    "\n",
    "        # generator params\n",
    "        z = tf.placeholder(tf.float32, shape=[None, z_dim])\n",
    "\n",
    "        G_W1 = tf.Variable(self.xavier_init([z_dim, h_dim]))\n",
    "        G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "        G_W2 = tf.Variable(self.xavier_init([h_dim, X_dim]))\n",
    "        G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "        theta_G = [G_W1, G_W2, G_b1, G_b2]\n",
    "        \n",
    "        return X, z, theta_D, theta_G\n",
    "    \n",
    "    def sample_z(self, m, n):\n",
    "        return np.random.uniform(-1., 1., size=[m, n])\n",
    "\n",
    "    def generator(self, z):\n",
    "        X, z, theta_D, theta_G = self.define_params()\n",
    "        G_W1, G_W2, G_b1, G_b2 = theta_G[0], theta_G[1], theta_G[2], theta_G[3]\n",
    "        \n",
    "        G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "        G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
    "        G_prob = tf.nn.sigmoid(G_log_prob)\n",
    "        return G_prob\n",
    "\n",
    "    def discriminator(self, x):\n",
    "        X, z, theta_D, theta_G = self.define_params()\n",
    "        D_W1, D_W2, D_b1, D_b2 = theta_D[0], theta_D[1], theta_D[2], theta_D[3]\n",
    "        \n",
    "        D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "        out = tf.matmul(D_h1, D_W2) + D_b2\n",
    "        return out\n",
    "    \n",
    "    def training(self):\n",
    "        X, z, theta_D, theta_G = self.define_params()\n",
    "        print(X, z, theta_D, theta_G)\n",
    "\n",
    "        G_sample = self.generator(z)\n",
    "        D_real = self.discriminator(X)\n",
    "        D_fake = self.discriminator(G_sample)\n",
    "\n",
    "        D_loss = tf.reduce_mean(D_real) - tf.reduce_mean(D_fake)\n",
    "        G_loss = -tf.reduce_mean(D_fake)\n",
    "\n",
    "        D_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4).minimize(-D_loss, var_list=theta_D))\n",
    "        G_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4).minimize(G_loss, var_list=theta_G))\n",
    "\n",
    "        clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in theta_D]\n",
    "\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        if not os.path.exists('out/'):\n",
    "            os.makedirs('out/')\n",
    "\n",
    "        i = 0\n",
    "        for it in range(1000000):\n",
    "            for _ in range(5):\n",
    "                X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "                _, D_loss_curr, _ = sess.run([D_solver, D_loss, clip_D],\n",
    "                                             feed_dict={X: X_mb, z: sample_z(mb_size, z_dim)})\n",
    "\n",
    "            _, G_loss_curr = sess.run([G_solver, G_loss],\n",
    "                                      feed_dict={z: sample_z(mb_size, z_dim)})\n",
    "\n",
    "            if it % 100 == 0:\n",
    "                print('Iter: {}; D loss: {:.4}; G_loss: {:.4}'.format(it, D_loss_curr, G_loss_curr))\n",
    "\n",
    "                if it % 1000 == 0:\n",
    "                    samples = sess.run(G_sample, feed_dict={z: sample_z(16, z_dim)})\n",
    "                    # save images\n",
    "                    fig = plot(samples)\n",
    "                    plt.savefig('out/{}.png'\n",
    "                                .format(str(i).zfill(3)), bbox_inches='tight')\n",
    "                    i += 1\n",
    "                    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'WGAN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ca2a089ece0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mh_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmnist_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'WGAN' is not defined"
     ]
    }
   ],
   "source": [
    "# apply wgan to mnist data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "mb_size = 32\n",
    "X_dim = 784\n",
    "z_dim = 20\n",
    "h_dim = 128\n",
    "\n",
    "mnist_train = WGAN(mb_size, X_dim, z_dim, h_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0; D loss: -0.003368; G_loss: -0.002383\n",
      "Iter: 100; D loss: 1.824; G_loss: 1.376\n",
      "Iter: 200; D loss: 1.781; G_loss: 1.229\n",
      "Iter: 300; D loss: 1.567; G_loss: 0.9889\n",
      "Iter: 400; D loss: 1.32; G_loss: 0.8205\n",
      "Iter: 500; D loss: 1.028; G_loss: 0.777\n",
      "Iter: 600; D loss: 0.7022; G_loss: 0.6411\n",
      "Iter: 700; D loss: 0.4505; G_loss: 0.5951\n",
      "Iter: 800; D loss: 0.3162; G_loss: 0.4934\n",
      "Iter: 900; D loss: 0.1659; G_loss: 0.3691\n",
      "Iter: 1000; D loss: 0.1118; G_loss: 0.05402\n",
      "Iter: 1100; D loss: 0.05006; G_loss: 0.04562\n",
      "Iter: 1200; D loss: 0.02963; G_loss: 0.004156\n",
      "Iter: 1300; D loss: 0.0206; G_loss: 0.01705\n",
      "Iter: 1400; D loss: 0.01558; G_loss: -0.02134\n",
      "Iter: 1500; D loss: 0.001415; G_loss: -0.04802\n",
      "Iter: 1600; D loss: 0.006767; G_loss: 0.006029\n",
      "Iter: 1700; D loss: 0.003845; G_loss: 0.04103\n",
      "Iter: 1800; D loss: 0.001434; G_loss: 0.0329\n",
      "Iter: 1900; D loss: -4.686e-05; G_loss: -0.09211\n",
      "Iter: 2000; D loss: 0.001947; G_loss: -0.03738\n",
      "Iter: 2100; D loss: 0.01005; G_loss: -0.01618\n",
      "Iter: 2200; D loss: 0.001043; G_loss: 0.005411\n",
      "Iter: 2300; D loss: 0.002742; G_loss: -0.005642\n",
      "Iter: 2400; D loss: 0.0009117; G_loss: 0.04385\n",
      "Iter: 2500; D loss: 0.002666; G_loss: -0.01062\n",
      "Iter: 2600; D loss: 0.00536; G_loss: -0.02911\n",
      "Iter: 2700; D loss: 0.0005567; G_loss: -0.009399\n",
      "Iter: 2800; D loss: 3.006e-05; G_loss: 0.03412\n",
      "Iter: 2900; D loss: 0.006366; G_loss: 0.06018\n",
      "Iter: 3000; D loss: 0.005003; G_loss: -0.06267\n",
      "Iter: 3100; D loss: 0.03607; G_loss: -0.0307\n",
      "Iter: 3200; D loss: 0.03769; G_loss: -0.02447\n",
      "Iter: 3300; D loss: 0.04688; G_loss: -0.03916\n",
      "Iter: 3400; D loss: 0.02815; G_loss: 0.01952\n",
      "Iter: 3500; D loss: 0.03802; G_loss: -0.01836\n",
      "Iter: 3600; D loss: 0.02879; G_loss: -0.0579\n",
      "Iter: 3700; D loss: 0.03648; G_loss: 0.04067\n",
      "Iter: 3800; D loss: 0.02994; G_loss: -0.04661\n",
      "Iter: 3900; D loss: 0.02662; G_loss: -0.0001712\n",
      "Iter: 4000; D loss: 0.04695; G_loss: 0.1161\n",
      "Iter: 4100; D loss: 0.03153; G_loss: 0.0202\n",
      "Iter: 4200; D loss: 0.03084; G_loss: 0.004374\n",
      "Iter: 4300; D loss: 0.03393; G_loss: -0.005771\n",
      "Iter: 4400; D loss: 0.02479; G_loss: -0.0008083\n",
      "Iter: 4500; D loss: 0.03797; G_loss: -0.03344\n",
      "Iter: 4600; D loss: 0.04775; G_loss: -0.01502\n",
      "Iter: 4700; D loss: 0.05061; G_loss: -0.01066\n",
      "Iter: 4800; D loss: 0.0645; G_loss: -0.006179\n",
      "Iter: 4900; D loss: 0.04477; G_loss: -0.02138\n",
      "Iter: 5000; D loss: 0.04633; G_loss: -0.01249\n",
      "Iter: 5100; D loss: 0.05019; G_loss: -0.00862\n",
      "Iter: 5200; D loss: 0.04189; G_loss: 0.01104\n",
      "Iter: 5300; D loss: 0.04197; G_loss: -0.01023\n",
      "Iter: 5400; D loss: 0.03813; G_loss: -0.009665\n",
      "Iter: 5500; D loss: 0.04803; G_loss: -0.0005483\n",
      "Iter: 5600; D loss: 0.03425; G_loss: -0.004924\n",
      "Iter: 5700; D loss: 0.0393; G_loss: -0.005454\n",
      "Iter: 5800; D loss: 0.0472; G_loss: -0.0118\n",
      "Iter: 5900; D loss: 0.04442; G_loss: -0.01243\n",
      "Iter: 6000; D loss: 0.03763; G_loss: -0.03749\n",
      "Iter: 6100; D loss: 0.05154; G_loss: -0.0136\n",
      "Iter: 6200; D loss: 0.05219; G_loss: -0.01271\n",
      "Iter: 6300; D loss: 0.05193; G_loss: -0.01117\n",
      "Iter: 6400; D loss: 0.05674; G_loss: -0.01335\n",
      "Iter: 6500; D loss: 0.0479; G_loss: -0.0144\n",
      "Iter: 6600; D loss: 0.0464; G_loss: -0.009415\n",
      "Iter: 6700; D loss: 0.04362; G_loss: -0.003766\n",
      "Iter: 6800; D loss: 0.04383; G_loss: -0.02188\n",
      "Iter: 6900; D loss: 0.04115; G_loss: -0.01302\n",
      "Iter: 7000; D loss: 0.0358; G_loss: -0.03259\n",
      "Iter: 7100; D loss: 0.04091; G_loss: -0.02007\n",
      "Iter: 7200; D loss: 0.04049; G_loss: -0.01896\n",
      "Iter: 7300; D loss: 0.04296; G_loss: -0.0189\n",
      "Iter: 7400; D loss: 0.03662; G_loss: -0.007448\n",
      "Iter: 7500; D loss: 0.03841; G_loss: -0.01156\n",
      "Iter: 7600; D loss: 0.0396; G_loss: -0.02462\n",
      "Iter: 7700; D loss: 0.04342; G_loss: -0.02254\n",
      "Iter: 7800; D loss: 0.0318; G_loss: -0.0137\n",
      "Iter: 7900; D loss: 0.03186; G_loss: -0.01854\n",
      "Iter: 8000; D loss: 0.03437; G_loss: -0.01339\n",
      "Iter: 8100; D loss: 0.0341; G_loss: -0.01812\n",
      "Iter: 8200; D loss: 0.04055; G_loss: -0.02106\n",
      "Iter: 8300; D loss: 0.04013; G_loss: -0.01788\n",
      "Iter: 8400; D loss: 0.03065; G_loss: -0.02336\n",
      "Iter: 8500; D loss: 0.03277; G_loss: -0.007923\n",
      "Iter: 8600; D loss: 0.02798; G_loss: -0.00696\n",
      "Iter: 8700; D loss: 0.03662; G_loss: -0.01968\n",
      "Iter: 8800; D loss: 0.03903; G_loss: -0.01456\n",
      "Iter: 8900; D loss: 0.03366; G_loss: -0.01515\n",
      "Iter: 9000; D loss: 0.03661; G_loss: -0.01857\n",
      "Iter: 9100; D loss: 0.03418; G_loss: -0.02113\n",
      "Iter: 9200; D loss: 0.0326; G_loss: -0.01214\n",
      "Iter: 9300; D loss: 0.03485; G_loss: -0.01317\n",
      "Iter: 9400; D loss: 0.02457; G_loss: -0.0172\n",
      "Iter: 9500; D loss: 0.03263; G_loss: -0.01697\n",
      "Iter: 9600; D loss: 0.02899; G_loss: -0.01544\n",
      "Iter: 9700; D loss: 0.03206; G_loss: -0.005748\n",
      "Iter: 9800; D loss: 0.03093; G_loss: -0.01282\n",
      "Iter: 9900; D loss: 0.0255; G_loss: -0.01308\n",
      "Iter: 10000; D loss: 0.02897; G_loss: -0.01531\n",
      "Iter: 10100; D loss: 0.02028; G_loss: -0.006687\n",
      "Iter: 10200; D loss: 0.02803; G_loss: -0.008701\n",
      "Iter: 10300; D loss: 0.02492; G_loss: -0.02409\n",
      "Iter: 10400; D loss: 0.02786; G_loss: -0.02041\n",
      "Iter: 10500; D loss: 0.0266; G_loss: -0.0005239\n",
      "Iter: 10600; D loss: 0.02783; G_loss: -0.01476\n",
      "Iter: 10700; D loss: 0.03114; G_loss: -0.01989\n",
      "Iter: 10800; D loss: 0.02664; G_loss: -0.01587\n",
      "Iter: 10900; D loss: 0.02118; G_loss: -0.0191\n",
      "Iter: 11000; D loss: 0.03066; G_loss: -0.01528\n",
      "Iter: 11100; D loss: 0.02953; G_loss: -0.02234\n",
      "Iter: 11200; D loss: 0.02434; G_loss: -0.01435\n",
      "Iter: 11300; D loss: 0.02822; G_loss: -0.01717\n",
      "Iter: 11400; D loss: 0.03159; G_loss: -0.01443\n",
      "Iter: 11500; D loss: 0.0246; G_loss: -0.01839\n",
      "Iter: 11600; D loss: 0.02473; G_loss: -0.01364\n",
      "Iter: 11700; D loss: 0.02426; G_loss: -0.01551\n",
      "Iter: 11800; D loss: 0.02221; G_loss: -0.01937\n",
      "Iter: 11900; D loss: 0.02969; G_loss: -0.02032\n",
      "Iter: 12000; D loss: 0.02507; G_loss: -0.01702\n",
      "Iter: 12100; D loss: 0.02979; G_loss: -0.00809\n",
      "Iter: 12200; D loss: 0.02896; G_loss: -0.008417\n",
      "Iter: 12300; D loss: 0.02923; G_loss: -0.0096\n",
      "Iter: 12400; D loss: 0.02821; G_loss: -0.004459\n",
      "Iter: 12500; D loss: 0.02436; G_loss: -0.009387\n",
      "Iter: 12600; D loss: 0.02592; G_loss: -0.008758\n",
      "Iter: 12700; D loss: 0.02473; G_loss: -0.007686\n",
      "Iter: 12800; D loss: 0.02413; G_loss: -0.01049\n",
      "Iter: 12900; D loss: 0.02502; G_loss: -0.009749\n",
      "Iter: 13000; D loss: 0.02512; G_loss: -0.00532\n",
      "Iter: 13100; D loss: 0.02927; G_loss: -0.006971\n",
      "Iter: 13200; D loss: 0.02527; G_loss: -0.0089\n",
      "Iter: 13300; D loss: 0.02162; G_loss: -0.005964\n",
      "Iter: 13400; D loss: 0.02728; G_loss: -0.00999\n",
      "Iter: 13500; D loss: 0.02347; G_loss: -0.007725\n",
      "Iter: 13600; D loss: 0.02326; G_loss: -0.006345\n",
      "Iter: 13700; D loss: 0.0299; G_loss: -0.01051\n",
      "Iter: 13800; D loss: 0.02989; G_loss: -0.009994\n",
      "Iter: 13900; D loss: 0.02703; G_loss: -0.006428\n",
      "Iter: 14000; D loss: 0.02945; G_loss: -0.01077\n",
      "Iter: 14100; D loss: 0.02986; G_loss: -0.009439\n",
      "Iter: 14200; D loss: 0.02656; G_loss: -0.01173\n",
      "Iter: 14300; D loss: 0.0246; G_loss: -0.01172\n",
      "Iter: 14400; D loss: 0.0228; G_loss: -0.01268\n",
      "Iter: 14500; D loss: 0.01928; G_loss: -0.01307\n",
      "Iter: 14600; D loss: 0.02682; G_loss: -0.01204\n",
      "Iter: 14700; D loss: 0.02485; G_loss: -0.006625\n",
      "Iter: 14800; D loss: 0.02438; G_loss: -0.01009\n",
      "Iter: 14900; D loss: 0.01889; G_loss: -0.01165\n",
      "Iter: 15000; D loss: 0.02315; G_loss: -0.01168\n",
      "Iter: 15100; D loss: 0.02134; G_loss: -0.009647\n",
      "Iter: 15200; D loss: 0.02513; G_loss: -0.01139\n",
      "Iter: 15300; D loss: 0.02348; G_loss: -0.01213\n",
      "Iter: 15400; D loss: 0.02253; G_loss: -0.009392\n",
      "Iter: 15500; D loss: 0.01963; G_loss: -0.009207\n",
      "Iter: 15600; D loss: 0.02758; G_loss: -0.009514\n",
      "Iter: 15700; D loss: 0.02291; G_loss: -0.01194\n",
      "Iter: 15800; D loss: 0.02475; G_loss: -0.009711\n",
      "Iter: 15900; D loss: 0.02271; G_loss: -0.009066\n",
      "Iter: 16000; D loss: 0.02302; G_loss: -0.01229\n",
      "Iter: 16100; D loss: 0.02288; G_loss: -0.01024\n",
      "Iter: 16200; D loss: 0.02464; G_loss: -0.01269\n",
      "Iter: 16300; D loss: 0.02266; G_loss: -0.01195\n",
      "Iter: 16400; D loss: 0.0235; G_loss: -0.011\n",
      "Iter: 16500; D loss: 0.02529; G_loss: -0.01331\n",
      "Iter: 16600; D loss: 0.02236; G_loss: -0.01218\n",
      "Iter: 16700; D loss: 0.02555; G_loss: -0.01145\n",
      "Iter: 16800; D loss: 0.02138; G_loss: -0.01664\n",
      "Iter: 16900; D loss: 0.02393; G_loss: -0.01446\n",
      "Iter: 17000; D loss: 0.02271; G_loss: -0.009744\n",
      "Iter: 17100; D loss: 0.01996; G_loss: -0.0114\n",
      "Iter: 17200; D loss: 0.02219; G_loss: -0.009385\n",
      "Iter: 17300; D loss: 0.02229; G_loss: -0.01104\n",
      "Iter: 17400; D loss: 0.02457; G_loss: -0.01194\n",
      "Iter: 17500; D loss: 0.02202; G_loss: -0.01167\n",
      "Iter: 17600; D loss: 0.01836; G_loss: -0.01057\n",
      "Iter: 17700; D loss: 0.02102; G_loss: -0.009978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 17800; D loss: 0.01955; G_loss: -0.01237\n",
      "Iter: 17900; D loss: 0.02324; G_loss: -0.01335\n",
      "Iter: 18000; D loss: 0.02576; G_loss: -0.01381\n",
      "Iter: 18100; D loss: 0.02187; G_loss: -0.01243\n",
      "Iter: 18200; D loss: 0.01861; G_loss: -0.01083\n",
      "Iter: 18300; D loss: 0.01896; G_loss: -0.01066\n",
      "Iter: 18400; D loss: 0.02239; G_loss: -0.01485\n",
      "Iter: 18500; D loss: 0.01822; G_loss: -0.01556\n",
      "Iter: 18600; D loss: 0.01878; G_loss: -0.0114\n",
      "Iter: 18700; D loss: 0.02235; G_loss: -0.01545\n",
      "Iter: 18800; D loss: 0.0246; G_loss: -0.01372\n",
      "Iter: 18900; D loss: 0.02209; G_loss: -0.01133\n",
      "Iter: 19000; D loss: 0.01907; G_loss: -0.01564\n",
      "Iter: 19100; D loss: 0.0217; G_loss: -0.008271\n",
      "Iter: 19200; D loss: 0.02054; G_loss: -0.01304\n",
      "Iter: 19300; D loss: 0.02038; G_loss: -0.01228\n",
      "Iter: 19400; D loss: 0.02125; G_loss: -0.0108\n",
      "Iter: 19500; D loss: 0.02329; G_loss: -0.01193\n",
      "Iter: 19600; D loss: 0.01949; G_loss: -0.01435\n",
      "Iter: 19700; D loss: 0.01636; G_loss: -0.01169\n",
      "Iter: 19800; D loss: 0.0219; G_loss: -0.009502\n",
      "Iter: 19900; D loss: 0.01848; G_loss: -0.01255\n",
      "Iter: 20000; D loss: 0.02296; G_loss: -0.01364\n",
      "Iter: 20100; D loss: 0.0162; G_loss: -0.01088\n",
      "Iter: 20200; D loss: 0.01956; G_loss: -0.01356\n",
      "Iter: 20300; D loss: 0.02168; G_loss: -0.01079\n",
      "Iter: 20400; D loss: 0.02323; G_loss: -0.01078\n",
      "Iter: 20500; D loss: 0.02006; G_loss: -0.01408\n",
      "Iter: 20600; D loss: 0.01958; G_loss: -0.01246\n",
      "Iter: 20700; D loss: 0.0196; G_loss: -0.01443\n",
      "Iter: 20800; D loss: 0.01624; G_loss: -0.01117\n",
      "Iter: 20900; D loss: 0.01984; G_loss: -0.009662\n",
      "Iter: 21000; D loss: 0.02312; G_loss: -0.01682\n",
      "Iter: 21100; D loss: 0.01829; G_loss: -0.008103\n",
      "Iter: 21200; D loss: 0.01853; G_loss: -0.01043\n",
      "Iter: 21300; D loss: 0.02098; G_loss: -0.0122\n",
      "Iter: 21400; D loss: 0.0198; G_loss: -0.01488\n",
      "Iter: 21500; D loss: 0.02031; G_loss: -0.01203\n",
      "Iter: 21600; D loss: 0.02038; G_loss: -0.0108\n",
      "Iter: 21700; D loss: 0.0183; G_loss: -0.008294\n",
      "Iter: 21800; D loss: 0.02165; G_loss: -0.01184\n",
      "Iter: 21900; D loss: 0.01565; G_loss: -0.01044\n",
      "Iter: 22000; D loss: 0.01887; G_loss: -0.01194\n",
      "Iter: 22100; D loss: 0.0183; G_loss: -0.01051\n",
      "Iter: 22200; D loss: 0.0204; G_loss: -0.01334\n",
      "Iter: 22300; D loss: 0.01888; G_loss: -0.0127\n",
      "Iter: 22400; D loss: 0.01773; G_loss: -0.01157\n",
      "Iter: 22500; D loss: 0.02062; G_loss: -0.009037\n",
      "Iter: 22600; D loss: 0.0206; G_loss: -0.01005\n",
      "Iter: 22700; D loss: 0.01561; G_loss: -0.01145\n",
      "Iter: 22800; D loss: 0.01756; G_loss: -0.01476\n",
      "Iter: 22900; D loss: 0.01933; G_loss: -0.01335\n",
      "Iter: 23000; D loss: 0.01863; G_loss: -0.01089\n",
      "Iter: 23100; D loss: 0.01669; G_loss: -0.01354\n",
      "Iter: 23200; D loss: 0.01783; G_loss: -0.01259\n",
      "Iter: 23300; D loss: 0.0166; G_loss: -0.01157\n",
      "Iter: 23400; D loss: 0.01605; G_loss: -0.01293\n",
      "Iter: 23500; D loss: 0.01778; G_loss: -0.00902\n",
      "Iter: 23600; D loss: 0.01682; G_loss: -0.009685\n",
      "Iter: 23700; D loss: 0.01966; G_loss: -0.01043\n",
      "Iter: 23800; D loss: 0.01825; G_loss: -0.01128\n",
      "Iter: 23900; D loss: 0.01769; G_loss: -0.01371\n",
      "Iter: 24000; D loss: 0.01656; G_loss: -0.01266\n",
      "Iter: 24100; D loss: 0.01717; G_loss: -0.01564\n",
      "Iter: 24200; D loss: 0.01949; G_loss: -0.01396\n",
      "Iter: 24300; D loss: 0.02027; G_loss: -0.01219\n",
      "Iter: 24400; D loss: 0.01948; G_loss: -0.01147\n",
      "Iter: 24500; D loss: 0.01444; G_loss: -0.01023\n",
      "Iter: 24600; D loss: 0.01481; G_loss: -0.01264\n",
      "Iter: 24700; D loss: 0.01848; G_loss: -0.01442\n",
      "Iter: 24800; D loss: 0.01749; G_loss: -0.0123\n",
      "Iter: 24900; D loss: 0.01699; G_loss: -0.01139\n",
      "Iter: 25000; D loss: 0.02022; G_loss: -0.01318\n",
      "Iter: 25100; D loss: 0.01657; G_loss: -0.01359\n",
      "Iter: 25200; D loss: 0.01731; G_loss: -0.01084\n",
      "Iter: 25300; D loss: 0.01732; G_loss: -0.01244\n",
      "Iter: 25400; D loss: 0.01702; G_loss: -0.01479\n",
      "Iter: 25500; D loss: 0.01465; G_loss: -0.009185\n",
      "Iter: 25600; D loss: 0.01435; G_loss: -0.01031\n",
      "Iter: 25700; D loss: 0.01701; G_loss: -0.01134\n",
      "Iter: 25800; D loss: 0.01934; G_loss: -0.01417\n",
      "Iter: 25900; D loss: 0.01724; G_loss: -0.01184\n",
      "Iter: 26000; D loss: 0.02105; G_loss: -0.01289\n",
      "Iter: 26100; D loss: 0.0165; G_loss: -0.01059\n",
      "Iter: 26200; D loss: 0.0127; G_loss: -0.009198\n",
      "Iter: 26300; D loss: 0.01344; G_loss: -0.01259\n",
      "Iter: 26400; D loss: 0.01569; G_loss: -0.01128\n",
      "Iter: 26500; D loss: 0.01749; G_loss: -0.008275\n",
      "Iter: 26600; D loss: 0.01608; G_loss: -0.01528\n",
      "Iter: 26700; D loss: 0.01668; G_loss: -0.01302\n",
      "Iter: 26800; D loss: 0.01775; G_loss: -0.01433\n",
      "Iter: 26900; D loss: 0.01472; G_loss: -0.01232\n",
      "Iter: 27000; D loss: 0.01691; G_loss: -0.01433\n",
      "Iter: 27100; D loss: 0.01259; G_loss: -0.009978\n",
      "Iter: 27200; D loss: 0.01518; G_loss: -0.01143\n",
      "Iter: 27300; D loss: 0.01592; G_loss: -0.0119\n",
      "Iter: 27400; D loss: 0.01476; G_loss: -0.01078\n",
      "Iter: 27500; D loss: 0.0165; G_loss: -0.01194\n",
      "Iter: 27600; D loss: 0.01752; G_loss: -0.01077\n",
      "Iter: 27700; D loss: 0.01608; G_loss: -0.01139\n",
      "Iter: 27800; D loss: 0.01744; G_loss: -0.01131\n",
      "Iter: 27900; D loss: 0.0128; G_loss: -0.01269\n",
      "Iter: 28000; D loss: 0.01763; G_loss: -0.01373\n",
      "Iter: 28100; D loss: 0.01615; G_loss: -0.008115\n",
      "Iter: 28200; D loss: 0.01378; G_loss: -0.01578\n",
      "Iter: 28300; D loss: 0.01668; G_loss: -0.01185\n",
      "Iter: 28400; D loss: 0.01784; G_loss: -0.01244\n",
      "Iter: 28500; D loss: 0.0143; G_loss: -0.01043\n",
      "Iter: 28600; D loss: 0.01408; G_loss: -0.01087\n",
      "Iter: 28700; D loss: 0.01378; G_loss: -0.009507\n",
      "Iter: 28800; D loss: 0.0139; G_loss: -0.01362\n",
      "Iter: 28900; D loss: 0.01677; G_loss: -0.0131\n",
      "Iter: 29000; D loss: 0.01766; G_loss: -0.01372\n",
      "Iter: 29100; D loss: 0.01214; G_loss: -0.01336\n",
      "Iter: 29200; D loss: 0.01672; G_loss: -0.0167\n",
      "Iter: 29300; D loss: 0.01443; G_loss: -0.009453\n",
      "Iter: 29400; D loss: 0.0155; G_loss: -0.0141\n",
      "Iter: 29500; D loss: 0.01586; G_loss: -0.01094\n",
      "Iter: 29600; D loss: 0.01814; G_loss: -0.01549\n",
      "Iter: 29700; D loss: 0.01521; G_loss: -0.01332\n",
      "Iter: 29800; D loss: 0.01226; G_loss: -0.01003\n",
      "Iter: 29900; D loss: 0.01914; G_loss: -0.0127\n",
      "Iter: 30000; D loss: 0.01667; G_loss: -0.01177\n",
      "Iter: 30100; D loss: 0.01509; G_loss: -0.01615\n",
      "Iter: 30200; D loss: 0.01809; G_loss: -0.01088\n",
      "Iter: 30300; D loss: 0.01364; G_loss: -0.01138\n",
      "Iter: 30400; D loss: 0.01382; G_loss: -0.01169\n",
      "Iter: 30500; D loss: 0.0137; G_loss: -0.009319\n",
      "Iter: 30600; D loss: 0.01705; G_loss: -0.01474\n",
      "Iter: 30700; D loss: 0.01308; G_loss: -0.01014\n",
      "Iter: 30800; D loss: 0.01744; G_loss: -0.01051\n",
      "Iter: 30900; D loss: 0.01495; G_loss: -0.00959\n",
      "Iter: 31000; D loss: 0.01463; G_loss: -0.01079\n",
      "Iter: 31100; D loss: 0.01578; G_loss: -0.009919\n",
      "Iter: 31200; D loss: 0.01359; G_loss: -0.01182\n",
      "Iter: 31300; D loss: 0.01612; G_loss: -0.01234\n",
      "Iter: 31400; D loss: 0.01275; G_loss: -0.009339\n",
      "Iter: 31500; D loss: 0.01622; G_loss: -0.01289\n",
      "Iter: 31600; D loss: 0.01345; G_loss: -0.01331\n",
      "Iter: 31700; D loss: 0.02106; G_loss: -0.01399\n",
      "Iter: 31800; D loss: 0.01404; G_loss: -0.01276\n",
      "Iter: 31900; D loss: 0.01633; G_loss: -0.01235\n",
      "Iter: 32000; D loss: 0.01247; G_loss: -0.01768\n",
      "Iter: 32100; D loss: 0.01735; G_loss: -0.0123\n",
      "Iter: 32200; D loss: 0.0158; G_loss: -0.0155\n",
      "Iter: 32300; D loss: 0.01474; G_loss: -0.01506\n",
      "Iter: 32400; D loss: 0.01324; G_loss: -0.01037\n",
      "Iter: 32500; D loss: 0.01549; G_loss: -0.009828\n",
      "Iter: 32600; D loss: 0.01472; G_loss: -0.0125\n",
      "Iter: 32700; D loss: 0.01639; G_loss: -0.01466\n",
      "Iter: 32800; D loss: 0.01687; G_loss: -0.01507\n",
      "Iter: 32900; D loss: 0.01591; G_loss: -0.01428\n",
      "Iter: 33000; D loss: 0.01719; G_loss: -0.01753\n",
      "Iter: 33100; D loss: 0.01578; G_loss: -0.01369\n",
      "Iter: 33200; D loss: 0.01411; G_loss: -0.01267\n",
      "Iter: 33300; D loss: 0.01505; G_loss: -0.008727\n",
      "Iter: 33400; D loss: 0.01807; G_loss: -0.0124\n",
      "Iter: 33500; D loss: 0.0144; G_loss: -0.00978\n",
      "Iter: 33600; D loss: 0.0154; G_loss: -0.01328\n",
      "Iter: 33700; D loss: 0.01471; G_loss: -0.00959\n",
      "Iter: 33800; D loss: 0.01745; G_loss: -0.01418\n",
      "Iter: 33900; D loss: 0.01838; G_loss: -0.01035\n",
      "Iter: 34000; D loss: 0.01468; G_loss: -0.009145\n",
      "Iter: 34100; D loss: 0.01594; G_loss: -0.0124\n",
      "Iter: 34200; D loss: 0.01309; G_loss: -0.01228\n",
      "Iter: 34300; D loss: 0.01374; G_loss: -0.01198\n",
      "Iter: 34400; D loss: 0.01641; G_loss: -0.0122\n",
      "Iter: 34500; D loss: 0.01375; G_loss: -0.00927\n",
      "Iter: 34600; D loss: 0.01498; G_loss: -0.01223\n",
      "Iter: 34700; D loss: 0.01729; G_loss: -0.01298\n",
      "Iter: 34800; D loss: 0.01364; G_loss: -0.01084\n",
      "Iter: 34900; D loss: 0.01849; G_loss: -0.01177\n",
      "Iter: 35000; D loss: 0.0149; G_loss: -0.01461\n",
      "Iter: 35100; D loss: 0.01233; G_loss: -0.01315\n",
      "Iter: 35200; D loss: 0.01026; G_loss: -0.01059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 35300; D loss: 0.01349; G_loss: -0.008861\n",
      "Iter: 35400; D loss: 0.01282; G_loss: -0.01511\n",
      "Iter: 35500; D loss: 0.01474; G_loss: -0.01323\n",
      "Iter: 35600; D loss: 0.01609; G_loss: -0.01276\n",
      "Iter: 35700; D loss: 0.01394; G_loss: -0.006258\n",
      "Iter: 35800; D loss: 0.01379; G_loss: -0.01392\n",
      "Iter: 35900; D loss: 0.0126; G_loss: -0.01146\n",
      "Iter: 36000; D loss: 0.01501; G_loss: -0.0147\n",
      "Iter: 36100; D loss: 0.01418; G_loss: -0.01065\n",
      "Iter: 36200; D loss: 0.01013; G_loss: -0.01043\n",
      "Iter: 36300; D loss: 0.01492; G_loss: -0.01137\n",
      "Iter: 36400; D loss: 0.01063; G_loss: -0.01081\n",
      "Iter: 36500; D loss: 0.01442; G_loss: -0.008802\n",
      "Iter: 36600; D loss: 0.01339; G_loss: -0.009972\n",
      "Iter: 36700; D loss: 0.01534; G_loss: -0.01395\n",
      "Iter: 36800; D loss: 0.01466; G_loss: -0.01043\n",
      "Iter: 36900; D loss: 0.01447; G_loss: -0.01262\n",
      "Iter: 37000; D loss: 0.01422; G_loss: -0.01042\n",
      "Iter: 37100; D loss: 0.01569; G_loss: -0.01369\n",
      "Iter: 37200; D loss: 0.01226; G_loss: -0.01079\n",
      "Iter: 37300; D loss: 0.01064; G_loss: -0.01055\n",
      "Iter: 37400; D loss: 0.01263; G_loss: -0.01036\n",
      "Iter: 37500; D loss: 0.01477; G_loss: -0.01196\n",
      "Iter: 37600; D loss: 0.01012; G_loss: -0.01191\n",
      "Iter: 37700; D loss: 0.01505; G_loss: -0.008173\n",
      "Iter: 37800; D loss: 0.01499; G_loss: -0.01085\n",
      "Iter: 37900; D loss: 0.01245; G_loss: -0.01036\n",
      "Iter: 38000; D loss: 0.01397; G_loss: -0.01112\n",
      "Iter: 38100; D loss: 0.01065; G_loss: -0.01418\n",
      "Iter: 38200; D loss: 0.0143; G_loss: -0.01131\n",
      "Iter: 38300; D loss: 0.01528; G_loss: -0.01146\n",
      "Iter: 38400; D loss: 0.01258; G_loss: -0.01255\n",
      "Iter: 38500; D loss: 0.01549; G_loss: -0.01404\n",
      "Iter: 38600; D loss: 0.01421; G_loss: -0.01115\n",
      "Iter: 38700; D loss: 0.01518; G_loss: -0.01136\n",
      "Iter: 38800; D loss: 0.01334; G_loss: -0.0113\n",
      "Iter: 38900; D loss: 0.01371; G_loss: -0.01109\n",
      "Iter: 39000; D loss: 0.01336; G_loss: -0.01354\n",
      "Iter: 39100; D loss: 0.01256; G_loss: -0.01513\n",
      "Iter: 39200; D loss: 0.01413; G_loss: -0.01109\n",
      "Iter: 39300; D loss: 0.01155; G_loss: -0.009985\n",
      "Iter: 39400; D loss: 0.01579; G_loss: -0.01332\n",
      "Iter: 39500; D loss: 0.01301; G_loss: -0.0128\n",
      "Iter: 39600; D loss: 0.01405; G_loss: -0.01412\n",
      "Iter: 39700; D loss: 0.01389; G_loss: -0.01207\n",
      "Iter: 39800; D loss: 0.01303; G_loss: -0.00957\n",
      "Iter: 39900; D loss: 0.0117; G_loss: -0.01179\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-30d36725baba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         _, D_loss_curr, _ = sess.run(\n\u001b[1;32m     28\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mD_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_D\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         )\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#     print(\"Dreal\", D_really)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlWorks/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlWorks/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlWorks/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlWorks/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlWorks/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mnist_train.training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://wiseodd.github.io/img/2017-02-04-wasserstein-gan/00.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, th=0.1):\n",
    "    return tf.maximum(th * x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(64, 64), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(m, n):\n",
    "#     return np.random.uniform(-1., 1., size=[m, n])\n",
    "     return np.random.normal(0, 1, (m, 1, 1, 100))\n",
    "\n",
    "\n",
    "def generator(x, isTrain=True, reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "\n",
    "        # 1st hidden layer\n",
    "        conv1 = tf.layers.conv2d_transpose(x, 1024, [4, 4], strides=(1, 1), padding='valid')\n",
    "        lrelu1 = lrelu(tf.layers.batch_normalization(conv1, training=isTrain), 0.2)\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        conv2 = tf.layers.conv2d_transpose(lrelu1, 512, [4, 4], strides=(2, 2), padding='same')\n",
    "        lrelu2 = lrelu(tf.layers.batch_normalization(conv2, training=isTrain), 0.2)\n",
    "\n",
    "        # 3rd hidden layer\n",
    "        conv3 = tf.layers.conv2d_transpose(lrelu2, 256, [4, 4], strides=(2, 2), padding='same')\n",
    "        lrelu3 = lrelu(tf.layers.batch_normalization(conv3, training=isTrain), 0.2)\n",
    "\n",
    "        # 4th hidden layer\n",
    "        conv4 = tf.layers.conv2d_transpose(lrelu3, 128, [4, 4], strides=(2, 2), padding='same')\n",
    "        lrelu4 = lrelu(tf.layers.batch_normalization(conv4, training=isTrain), 0.2)\n",
    "\n",
    "        # output layer\n",
    "        conv5 = tf.layers.conv2d_transpose(lrelu4, 1, [4, 4], strides=(2, 2), padding='same')\n",
    "        o = tf.nn.tanh(conv5)\n",
    "\n",
    "        return o\n",
    "\n",
    "# D(x)\n",
    "def discriminator(x, isTrain=True, reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # 1st hidden layer\n",
    "        conv1 = tf.layers.conv2d(x, 128, [4, 4], strides=(2, 2), padding='same')\n",
    "        lrelu1 = lrelu(conv1, 0.2)\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        conv2 = tf.layers.conv2d(lrelu1, 256, [4, 4], strides=(2, 2), padding='same')\n",
    "        lrelu2 = lrelu(tf.layers.batch_normalization(conv2, training=isTrain), 0.2)\n",
    "\n",
    "        # 3rd hidden layer\n",
    "        conv3 = tf.layers.conv2d(lrelu2, 512, [4, 4], strides=(2, 2), padding='same')\n",
    "        lrelu3 = lrelu(tf.layers.batch_normalization(conv3, training=isTrain), 0.2)\n",
    "\n",
    "        # 4th hidden layer\n",
    "        conv4 = tf.layers.conv2d(lrelu3, 1024, [4, 4], strides=(2, 2), padding='same')\n",
    "        lrelu4 = lrelu(tf.layers.batch_normalization(conv4, training=isTrain), 0.2)\n",
    "\n",
    "        # output layer\n",
    "        conv5 = tf.layers.conv2d(lrelu4, 1, [4, 4], strides=(1, 1), padding='valid')\n",
    "        o = tf.nn.sigmoid(conv5)\n",
    "\n",
    "        return o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# elif MODE == 'wgan-gp':\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=(None, 64, 64, 1))\n",
    "z = tf.placeholder(tf.float32, shape=(None, 1, 1, 100))\n",
    "\n",
    "G_sample = generator(z)\n",
    "D_real = discriminator(X)\n",
    "D_fake = discriminator(G_sample, reuse=True)\n",
    "\n",
    "LAMBDA = 10 #Gradient penalty lambda hyperparameter\n",
    "D_loss = tf.reduce_mean(D_real) - tf.reduce_mean(D_fake)\n",
    "G_loss = -tf.reduce_mean(D_fake)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "alpha = tf.random_uniform(\n",
    "    shape=[mb_size,64, 64, 1], \n",
    "    minval=0.,\n",
    "    maxval=1.\n",
    ")\n",
    "differences = D_fake - D_real\n",
    "print(differences.shape)\n",
    "interpolates = D_real + (alpha*differences)\n",
    "gradients = tf.gradients(discriminator(interpolates, reuse=True), [interpolates])[0]\n",
    "slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "D_loss += LAMBDA*gradient_penalty\n",
    "\n",
    "\n",
    "T_vars = tf.trainable_variables()\n",
    "D_vars = [var for var in T_vars if var.name.startswith('discriminator')]\n",
    "G_vars = [var for var in T_vars if var.name.startswith('generator')]\n",
    "\n",
    "G_solver = tf.train.AdamOptimizer(\n",
    "    learning_rate=1e-4, \n",
    "    beta1=0.5,\n",
    "    beta2=0.9\n",
    ").minimize(G_loss, var_list=G_vars)\n",
    "\n",
    "# D_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4)\n",
    "#             .minimize(-D_loss, var_list=theta_D))\n",
    "\n",
    "D_solver = tf.train.AdamOptimizer(\n",
    "    learning_rate=1e-4, \n",
    "    beta1=0.5, \n",
    "    beta2=0.9\n",
    ").minimize(D_loss, var_list=D_vars)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# clip_disc_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True, reshape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0; D loss: 4.07; G_loss: -0.0001175\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'out_improvedGAN/000.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6036d40c29f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         plt.savefig('out_improvedGAN/{}.png'\n\u001b[0;32m---> 38\u001b[0;31m                     .format(str(i).zfill(3)), bbox_inches='tight')\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fall_2017/dl_tf/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fall_2017/dl_tf/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fall_2017/dl_tf/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2250\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m   2253\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fall_2017/dl_tf/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'out_improvedGAN/000.png'"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('out_improvedGAN_dgscan/'):\n",
    "    os.makedirs('out_improvedGAN_dgscan/')\n",
    "\n",
    "i = 0\n",
    "\n",
    "# MNIST resize and normalization\n",
    "train_set = tf.image.resize_images(mnist.train.images, [64, 64]).eval(session=sess)\n",
    "train_set = (train_set - 0.5) / 0.5  # normalization; range: -1 ~ 1\n",
    "       \n",
    "        \n",
    "\n",
    "for it in range(10000):\n",
    "    for _ in range(5):\n",
    "        \n",
    "#         X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "        X_mb = train_set[it*mb_size:(it+1)*mb_size]\n",
    "\n",
    "        _, D_loss_curr = sess.run(\n",
    "            [D_solver, D_loss],\n",
    "            feed_dict={X: X_mb, z: sample_z(mb_size, z_dim)}\n",
    "        )\n",
    "\n",
    "    _, G_loss_curr = sess.run(\n",
    "        [G_solver, G_loss],\n",
    "        feed_dict={z: sample_z(mb_size, z_dim)}\n",
    "    )\n",
    "\n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {}; D loss: {:.4}; G_loss: {:.4}'\n",
    "              .format(it, D_loss_curr, G_loss_curr))\n",
    "        samples = sess.run(G_sample, feed_dict={z: sample_z(16, z_dim)})\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('out_improvedGAN/{}.png'\n",
    "                    .format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
